
import Random
using DiffEqFlux, Lux

# Functions to initialize different neural networks 


function initialize_neural_network(; saveat, input::Int, neurons, output::Int, activation = nothing)
	"""
		Function to initialize the neural network as well as the structure. 
		For more NNs in a model, this function can be called mulitple times. 
		
		input: 
            saveat: location for the structure to be stored, should be @__DIR__
			input: Int that dictates the number of inputs 
			output: Int that dictates the number of outputs 
			neurons : vector with integers where length of vector is number of layers
			activation: should be a tuple of length equal to layers, containing activation functions for each layer

		output:
			nn: neural Network
			p_init: initial parameters for the neural network 
			st: structure of the neural netowrk
	"""

	if typeof(neurons) == Int
		neurons = [neurons]
    elseif typeof(neurons) != Vector{Int}
        throw("Neurons should be either an Int or vector of Int")
	end

	layers = length(neurons)

	if typeof(activation) === nothing
		activation = ntuple(_ -> identity, layers)
	elseif Base.typename(typeof(activation)) != Base.typename(Tuple)
		throw("Activation functions should be a tuple, i.e., (activation, ) or nothing")
	elseif length(activation) != layers +1
		println("Activations should be length of layers + 1.")
		println("If only using a single activation function for a single layer, the activation function for the output was not assigned.")
		println("Therefore, it should be assigned as (activation_function, identity)")
		throw("Hence, fill up the remaining activation functions w. identity to match the length of layers + 1")
	end


	# initialize networks using random w. constant seed
	rng = Random.default_rng()
	Random.seed!(rng, 2)

	# Structure of nn
	if layers == 1
		nn = Lux.Chain(
			Lux.Dense(input, neurons[1], activation[1]),
			Lux.Dense(neurons[1], output, activation[2])
			)

	elseif layers == 2
		nn = Lux.Chain(
			Lux.Dense(input, neurons[1], activation[1]),
			Lux.Dense(neurons[1], neurons[2], activation[2]),
			Lux.Dense(neurons[2], output, activation[3])
			)

    elseif layers == 3
		nn = Lux.Chain(
			Lux.Dense(input, neurons[1], activation[1]),
			Lux.Dense(neurons[1], neurons[2], activation[2]),
            Lux.Dense(neurons[2], neurons[3], activation[3]),
			Lux.Dense(neurons[3], output, activation[4])
			)
	else 
		throw("More than 3 layers should not be necessary, cmon")
	end

	p_init, st = Lux.setup(rng, nn)

    # save model structure as a named tuple 
    meta_model_info = (input = [input], output = [output], neurons = neurons, activation=[join(string.(activation), ", ")])
    CSV.write(joinpath(saveat, "meta_model_info.csv"), meta_model_info)

	return nn, p_init, st

end


function load_neural_network(; saveat)
	"""
		Function to neural network structure from csv file generated by initialize_neural_network 
		
		input: 
            saveat: location where the structure is stored, should be @__DIR__

		output:
			nn: neural Network
			p_init: initial parameters for the neural network 
			st: structure of the neural netowrk
	"""

    meta_model_info = CSV.read(joinpath(saveat, "meta_model_info.csv"), DataFrame)
    activation_tuple = eval(Meta.parse("($(meta_model_info.activation[1]))"))

    nn, p_init, st = initialize_neural_network(saveat = saveat, input=meta_model_info.input[1], neurons = meta_model_info.neurons, output = meta_model_info.output[1], activation = activation_tuple)

	return nn, p_init, st

end